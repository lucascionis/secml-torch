{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7072795",
   "metadata": {},
   "source": [
    "# Using a Different Loss in the PGD Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a600be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr \n",
    "try:\n",
    "    import secmlt\n",
    "except ImportError:\n",
    "    %pip install git+https://github.com/pralab/secml-torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596d6b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%` not found.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from robustbench.utils import download_gdrive\n",
    "from secmlt.adv.backends import Backends\n",
    "from secmlt.adv.evasion.perturbation_models import LpPerturbationModels\n",
    "from secmlt.adv.evasion.pgd import PGD, PGDNative\n",
    "from secmlt.metrics.classification import Accuracy\n",
    "from secmlt.models.pytorch.base_pytorch_nn import BasePytorchClassifier\n",
    "from secmlt.optimization.losses import LogitDifferenceLoss\n",
    "from secmlt.trackers import (\n",
    "    GradientNormTracker,\n",
    "    LossTracker,\n",
    ")\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from utils.models import MNISTModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39029562",
   "metadata": {},
   "source": [
    "## Defensive distillation\n",
    "\n",
    "The defensive distillation method {cite:t}`papernot2016distillation` first trains an initial network $f$ on data $x$ with a softmax temperature of $T$. Then it uses the probability vector $f(x)$, which includes additional knowledge about classes compared to a class label, predicted by network $f$, to train a distilled network $f_d$ at temperature $T$ on the same data $x$.\n",
    "\n",
    "In other words, the network $f_d$ is trained using *soft labels*. In fact, they might not even be correct, but they are representation of what the model $f$ has learnt.\n",
    "\n",
    "![](../static/assets/tutorials/distillation.png)\n",
    "\n",
    "The idea behind this defense is that the student network should learn a \"hardened\" function that is constant around the tested samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da016572",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"1s7Kfa2Bs5nY2zLd6dVAxUqNbCNQhPYxs\"\n",
    "\n",
    "model = MNISTModel()\n",
    "path = Path(\"models/mnist_distilled.pt\")\n",
    "if not path.exists():\n",
    "    download_gdrive(MODEL_ID, path)\n",
    "state_dict = torch.load(\n",
    "    path, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    train=False,\n",
    "    root=\"data\",\n",
    "    download=True,\n",
    ")\n",
    "test_dataset = Subset(test_dataset, list(range(3)))\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "# Wrap model\n",
    "secmlt_model = BasePytorchClassifier(model)\n",
    "\n",
    "# Test accuracy on original data\n",
    "accuracy = Accuracy()(secmlt_model, test_loader)\n",
    "print(f\"test accuracy: {accuracy.item():.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run attack\n",
    "epsilon = 0.3\n",
    "num_steps = 200\n",
    "step_size = 0.005\n",
    "perturbation_model = LpPerturbationModels.LINF\n",
    "y_target = None\n",
    "\n",
    "trackers = [\n",
    "    LossTracker(),\n",
    "    GradientNormTracker(),\n",
    "]\n",
    "\n",
    "pgd = PGD(\n",
    "    perturbation_model=perturbation_model,\n",
    "    epsilon=epsilon,\n",
    "    num_steps=num_steps,\n",
    "    step_size=step_size,\n",
    "    random_start=False,\n",
    "    y_target=y_target,\n",
    "    backend=Backends.NATIVE,\n",
    "    trackers=trackers,\n",
    ")\n",
    "pgd_adv_ds = pgd(secmlt_model, test_loader)\n",
    "\n",
    "robust_accuracy = accuracy = Accuracy()(secmlt_model, pgd_adv_ds)\n",
    "print(f\"robust accuracy: {robust_accuracy.item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57daff0",
   "metadata": {},
   "source": [
    "The robust accuracy after the attack is almost the same as the original accuracy.\n",
    "Let's check again the loss function to understand the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4299d4b0",
   "metadata": {},
   "source": [
    "As the gradient update is defined as:\n",
    "\n",
    "$x_{i+1} = x_i + \\alpha \\nabla f(x_i, y, \\theta)$,\n",
    "\n",
    "there might be two possibilities. Either the step size is too small, or the gradient is zero!\n",
    "\n",
    "If the gradient is zero, the point $x_i$ is never updated!\n",
    "Let's check the size of the gradient (any norm is fine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d734a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_pgd = pgd.trackers[0].get()\n",
    "grad_nodrm_pgd = pgd.trackers[1].get()\n",
    "\n",
    "num_samples = loss_pgd.shape[0]\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=2, ncols=num_samples, figsize=(5 * num_samples, 4), sharey=True\n",
    ")\n",
    "\n",
    "for i in range(num_samples):\n",
    "    axes[0, i].plot(loss_pgd[i], linestyle=\"-\", alpha=0.9, label=\"PGD\")\n",
    "    axes[0, i].set_xlabel(\"Iteration\")\n",
    "    axes[0, i].set_ylabel(\"Loss\")\n",
    "    axes[0, i].set_title(f\"Sample {i}\")\n",
    "    axes[1, i].plot(grad_nodrm_pgd[i], linestyle=\"-\", alpha=0.9, label=\"PGD\")\n",
    "    axes[1, i].set_xlabel(\"Iteration\")\n",
    "    axes[1, i].set_ylabel(\"Gradient Norm\")\n",
    "\n",
    "\n",
    "# add one shared legend\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.92])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2e1155",
   "metadata": {},
   "source": [
    "The distillation defense leverages a specific trick that makes the softmax function saturate, hence making its computations on the gradient *unstable*.\n",
    "\n",
    "The softmax function is usually cascaded after DNNs to get outputs that look like probabilities, *i.e.*, to sum up to 1.\n",
    "\n",
    "This defense can be broken by removing the softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5edbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PGDWithDifferenceOfLogits(PGDNative):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_function = LogitDifferenceLoss()\n",
    "\n",
    "\n",
    "trackers = [\n",
    "    LossTracker(),\n",
    "    GradientNormTracker(),\n",
    "]\n",
    "\n",
    "adaptive_attack = PGDWithDifferenceOfLogits(\n",
    "    perturbation_model=perturbation_model,\n",
    "    epsilon=epsilon,\n",
    "    num_steps=num_steps,\n",
    "    step_size=step_size,\n",
    "    random_start=False,\n",
    "    y_target=y_target,\n",
    "    backend=Backends.NATIVE,\n",
    "    trackers=trackers,\n",
    ")\n",
    "\n",
    "adaptive_attack_ds = adaptive_attack(secmlt_model, test_loader)\n",
    "\n",
    "robust_accuracy = accuracy = Accuracy()(secmlt_model, adaptive_attack_ds)\n",
    "print(f\"robust accuracy: {robust_accuracy.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2b9d8a",
   "metadata": {},
   "source": [
    "Now we can display the gradient norm and the loss of the PGD attack with the difference of logits loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8bcc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_adaptive_pgd = adaptive_attack.trackers[0].get()\n",
    "grad_nodrm_adaptive_pgd = adaptive_attack.trackers[1].get()\n",
    "\n",
    "num_samples = loss_adaptive_pgd.shape[0]\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=2, ncols=num_samples, figsize=(5 * num_samples, 4), sharey=True\n",
    ")\n",
    "\n",
    "for i in range(num_samples):\n",
    "    axes[0, i].plot(loss_adaptive_pgd[i], linestyle=\"-\", alpha=0.9, label=\"Adaptive PGD\")\n",
    "    axes[0, i].set_xlabel(\"Iteration\")\n",
    "    axes[0, i].set_ylabel(\"Loss\")\n",
    "    axes[0, i].set_title(f\"Sample {i}\")\n",
    "    axes[0, i].grid(alpha=0.3)\n",
    "    axes[1, i].plot(grad_nodrm_adaptive_pgd[i], linestyle=\"-\", alpha=0.9, label=\"Adaptive PGD\")\n",
    "    axes[1, i].set_xlabel(\"Iteration\")\n",
    "    axes[1, i].set_ylabel(\"Gradient Norm\")\n",
    "\n",
    "\n",
    "# add one shared legend\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.92])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9003134f",
   "metadata": {},
   "source": [
    "Note that there is another straightforward way of finding adversarial examples for the student model.\n",
    "Hint: remember that the distilled network is learning an approximation of the teacher network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc86ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = '1qmjepc4k_o4BIqCvUJgwg-K19CaovOrQ'\n",
    "\n",
    "teacher_model = MNISTModel()\n",
    "teacher_path = Path('models/mnist_teacher.pt')\n",
    "if teacher_path.exists() is False:\n",
    "    download_gdrive(MODEL_ID, teacher_path)\n",
    "teacher_state_dict = torch.load(teacher_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "teacher_model.load_state_dict(teacher_state_dict)\n",
    "teacher_model.eval()\n",
    "\n",
    "# Wrap model\n",
    "secmlt_teacher_model = BasePytorchClassifier(teacher_model)\n",
    "\n",
    "# run PGD attack on teacher model\n",
    "teacher_adv_ds = pgd(secmlt_teacher_model, test_loader)\n",
    "\n",
    "# test robust accuracy of teacher model on adversarial examples found on itself\n",
    "robust_accuracy = accuracy = Accuracy()(secmlt_teacher_model, teacher_adv_ds)\n",
    "print(f\"teacher robust accuracy: {robust_accuracy.item():.2f}\")\n",
    "\n",
    "# test robust accuracy of student model on adversarial examples found on teacher model\n",
    "robust_accuracy = accuracy = Accuracy()(secmlt_model, teacher_adv_ds)\n",
    "print(f\"student robust accuracy on teacher adv examples: {robust_accuracy.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6174b498",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secmlt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
